{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample ML Project with Labelbox\n",
    "\n",
    "<b>Overview</b>\n",
    "* Retrieve Data from Labelbox\n",
    "* Transform Data\n",
    "* Pre-Process\n",
    "* Train Model\n",
    "* Optional - Upload Predictions to Labelbox Model Diagnostic tool\n",
    "* Optional - Upload Predictions for MAL\n",
    "\n",
    "### Usage\n",
    "- <b>Model Training</b>:\n",
    "  * Set a project ID containing polygons and segmentation labels\n",
    "  * Polygons will train the instance segmentation head\n",
    "  * Segmentation labels will train the semantic segmentation head\n",
    "- <b>Diagnostics</b>:\n",
    "  * No additional configuration is necessary. As long as the model has been   \n",
    "- <b>MAL</b>:\n",
    "  * Set a dataset ID for the dataset you would like to upload predictions to. A new project will automatically be created.\n",
    "trained this will work.\n",
    "\n",
    "### Suggested Workflow\n",
    "* To get the most out of Labelbox, we suggest training a model on a small amount of data, exploring model performance using diagnostics, selecting a dataset using catalog to address model shortcomings, make any model architecture adjustments, and then upload predictions via MAL made on this new dataset for faster labeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Setup with installation of libraries that are important for Model building and working with Labelbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch \\\n",
    "                torchvision \\\n",
    "                tensorflow\n",
    "!pip install -q \"git+https://github.com/Labelbox/labelbox-python@ms/coco#egg=labelbox[data]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Data from Labelbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert the API Key that can be generated: See more https://docs.labelbox.com/docs/create-an-api-key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = None\n",
    "# For training:\n",
    "project_id = \"\"\n",
    "# The model will make predictions on the following dataset \n",
    "# and upload predictions to a new project for model assisted labeling.\n",
    "mal_dataset_id = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import uuid\n",
    "import random\n",
    "import functools\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import requests\n",
    "\n",
    "from labelbox.schema.model import Model\n",
    "from labelbox.data.metrics.group import get_label_pairs\n",
    "from labelbox import LabelingFrontend, OntologyBuilder, Client\n",
    "from labelbox.data.metrics.iou import data_row_miou\n",
    "from labelbox.data.serialization import COCOConverter, NDJsonConverter\n",
    "from labelbox.data.annotation_types import (\n",
    "    Point,\n",
    "    Polygon,\n",
    "    Mask, \n",
    "    Label,\n",
    "    Rectangle, \n",
    "    Polygon,\n",
    "    LabelList,\n",
    "    ImageData,\n",
    "    MaskData,\n",
    "    ObjectAnnotation\n",
    ")\n",
    "\n",
    "#Feel free to insert any additional Imports as they are necessary for your Model Building. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(api_key = API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Config:\n",
    "* `project_id` - Indicates which project labels should be exported from.\n",
    "* `mal_dataset_id` - Dataset to use for MAL. We will create a new project in this notebook.\n",
    "* `image_root` - Where to write images to on disk\n",
    "* `mask_root` - Where to masks to on disk\n",
    "* `seg_masks_root` - Where to write the semantic segmentation masks\n",
    "* `train_json_instance_path` - Where the train partition of the instance data will be written\n",
    "* `train_json_panoptic_path` - Where the train partition of the panoptic data will be written\n",
    "* `test_json_instance_path` - Where the test partition of the instance data will be written\n",
    "* `test_json_panoptic_path` - Where the test partition of the panoptic data will be written\n",
    "* `train_test_split` - How much of the data to add to each parition (by percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_root = \"<insertPath>\"\n",
    "mask_root = \"<insertPath>\"\n",
    "seg_masks_root = \"<insertPath>\"\n",
    "train_json_instance_path = '<insertPath>\n",
    "train_json_panoptic_path = \"<insertPath>\"\n",
    "test_json_instance_path = '<insertPath>'\n",
    "test_json_panoptic_path = \"<insertPath>\"\n",
    "train_test_split = [0.8, 0.2]\n",
    "train_ds_name = \"<insertName>\"\n",
    "test_ds_name = \"<insertName>\"\n",
    "\n",
    "model_name = \"<insertProjectName>\"\n",
    "\n",
    "proj = client.get_project(project_id)\n",
    "labels = proj.label_generator().as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some labels aside for the val set.\n",
    "raw_data = labels._data\n",
    "labels = LabelList(raw_data[100:])\n",
    "val_labels = LabelList(raw_data[:100]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For More Information on how to download data see here: https://docs.labelbox.com/docs/export-labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert Code here to download and utilize the existing SDK to retrieve the Labelbox Data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This operation transforms the given image on the basis of the transform vector given by the user. \n",
    "\n",
    "https://colab.research.google.com/github/tensorflow/addons/blob/master/docs/tutorials/image_ops.ipynb#scrollTo=uheQOL-y0Fj3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert the Transformation for the Data that is required here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Read image\n",
    "* Resize imageÂ \n",
    "* Remove noise(Denoise)\n",
    "* Segmentation\n",
    "* Morphology(smoothing edges)\n",
    "\n",
    "\n",
    "For More examples see here: https://colab.research.google.com/github/Blaizzy/BiSeNet-Implementation/blob/master/Preprocessing.ipynb#scrollTo=pD3e08HvWsF3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert the Pre Processing Code here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is where the Magic happens. Depends on the Requirements feel free to add the code here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the model with the predictions that are created. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional - Upload Predictions to Labelbox Model Diagnostic tool "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more info: https://docs.labelbox.com/recipes/create-a-dataset\n",
    "Additional Example: https://colab.research.google.com/github/Labelbox/labelbox-python/blob/develop/examples/integrations/detectron2/coco_panoptic.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_mea = LabelList()\n",
    "with ThreadPoolExecutor(4) as executor:\n",
    "    futures = [executor.submit(get_label,label.data) for label in val_labels]\n",
    "    for future in tqdm(as_completed(futures)):\n",
    "        labels_mea.append(future.result())\n",
    "\n",
    "labels_mea.add_url_to_masks(signer) \\\n",
    "      .add_url_to_data(signer) \\\n",
    "      .assign_feature_schema_ids(OntologyBuilder.from_project(proj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the model already exists fetch it with the following:\n",
    "\n",
    "model = next(client.get_models(where = Model.name == model_name), None)\n",
    "if model is None:\n",
    "    model = client.create_model(model_name, ontology_id=proj.ontology().uid)\n",
    "\n",
    "\n",
    "# Increment model run version if it exists. Otherwise use the initial 0.0.0\n",
    "model_run_names = [model_run.name for model_run in model.model_runs()]\n",
    "if len(model_run_names):\n",
    "    model_run_names.sort(key=lambda s: [int(u) for u in s.split('.')])\n",
    "    latest_model_run_name = model_run_names[-1]\n",
    "    model_run_suffix = int(latest_model_run_name.split('.')[-1]) + 1\n",
    "    model_run_name = \".\".join([*latest_model_run_name.split('.')[:-1], str(model_run_suffix)])\n",
    "else:\n",
    "    model_run_name = \"0.0.0\"\n",
    "\n",
    "print(f\"Model Name: {model.name} | Model Run Version : {model_run_name}\")\n",
    "model_run = model.create_model_run(model_run_name)\n",
    "model_run.upsert_labels([label.uid for label in val_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_task = model_run.add_predictions(f'diagnostics-import-{uuid.uuid4()}', NDJsonConverter.serialize(labels_mea))\n",
    "upload_task.wait_until_done()\n",
    "print(upload_task.state)\n",
    "print(upload_task.errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, model_run_data_row in enumerate(model_run.model_run_data_rows()):\n",
    "    if idx == 5:\n",
    "        break\n",
    "    print(model_run_data_row.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional - Upload Predictions for MAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some additional unlabeled data rows\n",
    "dataset = client.get_dataset(mal_dataset_id) \n",
    "\n",
    "\n",
    "# Use ThreadPoolExecutor to parallelize image downloads.\n",
    "# This is still a bit slow due to the amount of processing for each data row.\n",
    "# For larger datasets this has to leverage multiprocessing.\n",
    "\n",
    "\n",
    "labels_mal = LabelList()\n",
    "with ThreadPoolExecutor(4) as executor:\n",
    "    data_rows = dataset.data_rows()\n",
    "    images = [ImageData(url = data_row.row_data, uid = data_row.uid, external_id = data_row.external_id) for data_row in data_rows]\n",
    "    futures = [executor.submit(get_label, image) for idx, image in enumerate(images) if idx < 25]\n",
    "    for future in tqdm(as_completed(futures)):\n",
    "        labels_mal.append(future.result())\n",
    "        \n",
    "project = client.create_project(name = \"<insertProjectName>\")\n",
    "editor = next(\n",
    "    client.get_labeling_frontends(where=LabelingFrontend.name == 'editor'))\n",
    "project.setup(editor, labels_mal.get_ontology().asdict())\n",
    "project.enable_model_assisted_labeling()\n",
    "project.datasets.connect(dataset)\n",
    "\n",
    "labels_mal.add_url_to_masks(signer) \\\n",
    "      .add_url_to_data(signer) \\\n",
    "      .assign_feature_schema_ids(OntologyBuilder.from_project(project))\n",
    "\n",
    "ndjsons = list(NDJsonConverter.serialize(labels_mal))\n",
    "upload_task = project.upload_annotations(name=f\"upload-job-{uuid.uuid4()}\",\n",
    "                                         annotations=ndjsons,\n",
    "                                         validate=False)\n",
    "# Wait for upload to finish\n",
    "upload_task.wait_until_done()\n",
    "# Review the upload status\n",
    "print(upload_task.errors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
